/*
 * Copyright (C) 2023-2024 Hedera Hashgraph, LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.hedera.services.bdd.spec.utilops.records;

import static com.hedera.node.app.hapi.utils.exports.recordstreaming.RecordStreamingUtils.parseRecordFileConsensusTime;
import static com.hedera.services.bdd.junit.support.StreamFileAccess.STREAM_FILE_ACCESS;
import static com.hedera.services.bdd.spec.queries.QueryVerbs.getTxnRecord;
import static com.hedera.services.bdd.spec.transactions.TxnVerbs.cryptoCreate;
import static com.hedera.services.bdd.spec.utilops.CustomSpecAssert.allRunFor;
import static com.hedera.services.bdd.suites.contract.Utils.asInstant;
import static java.util.Objects.requireNonNull;
import static java.util.stream.Collectors.toSet;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.google.protobuf.Descriptors;
import com.google.protobuf.GeneratedMessageV3;
import com.hedera.services.bdd.junit.SharedNetworkLauncherSessionListener;
import com.hedera.services.bdd.junit.support.StreamFileAccess;
import com.hedera.services.bdd.spec.HapiSpec;
import com.hedera.services.bdd.spec.utilops.UtilOp;
import com.hedera.services.bdd.spec.utilops.domain.ParsedItem;
import com.hedera.services.bdd.spec.utilops.domain.RecordSnapshot;
import com.hedera.services.bdd.spec.utilops.domain.SuiteSnapshots;
import com.hedera.services.bdd.suites.HapiSuite;
import com.hederahashgraph.api.proto.java.AccountID;
import com.hederahashgraph.api.proto.java.ContractID;
import com.hederahashgraph.api.proto.java.FileID;
import com.hederahashgraph.api.proto.java.ResponseCodeEnum;
import com.hederahashgraph.api.proto.java.ScheduleID;
import com.hederahashgraph.api.proto.java.TokenID;
import com.hederahashgraph.api.proto.java.TopicID;
import edu.umd.cs.findbugs.annotations.NonNull;
import java.io.File;
import java.io.IOException;
import java.io.UncheckedIOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.EnumSet;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import java.util.Set;
import java.util.function.Supplier;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.junit.jupiter.api.Assertions;

/**
 * A utility operation that either,
 * <ol>
 *     <li>Takes a snapshot of the record stream generated by running a {@link HapiSpec}; or,</li>
 *     <li>Fuzzy-matches the record stream generated by a {@link HapiSpec} against a prior snapshot.</li>
 * </ol>
 * The generated streams may come from either the <i>hedera-node/data/recordstreams/record0.0.3</i>
 * directory created by starting a local node; or the <i>hedera-node/test-clients/build/hapi-test/HAPI Tests/node0</i>
 * directory created by running a spec as a {@link com.hedera.services.bdd.junit.HapiTest}.
 *
 * <p>A "fuzzy-match" is a recursive comparison of two {@link com.google.protobuf.GeneratedMessageV3} messages that
 * ignores the natural variation that occurs in fields like timestamps and hashes when tests are re-rerun. The set
 * of field names to skip is given by {@link #FIELDS_TO_SKIP_IN_FUZZY_MATCH}; and for each snapshot we remember a
 * "placeholder" entity number that gives the number of entities that happened to be in state when the snapshot was
 * taken. This lets us "normalize" any entity ids in the stream (e.g., {@link AccountID}) and compare them against
 * the corresponding normalized ids in the snapshot.
 *
 * <p><b>IMPORTANT</b> - The initial set of fields to skip is almost certainly incomplete. As we encounter new
 * fields that vary between test runs, we should add them to the set. The goal is to make the fuzzy match as
 * deterministic as possible, so that we can be confident that the test is failing for the right reason.
 */
// too many parameters, repeated string literals
@SuppressWarnings({"java:S5960", "java:S1192"})
public class SnapshotModeOp extends UtilOp implements SnapshotOp {
    private static final Logger log = LogManager.getLogger(SnapshotModeOp.class);
    private static final long MIN_GZIP_SIZE_IN_BYTES = 26;
    private static final long MAX_NORMAL_FEE_VARIATION_IN_TINYBARS = 1;
    // For large key structures, there can be "significant" fee variation in tinybar units
    // due to different public key sizes and signature map prefixes
    private static final long MAX_COMPLEX_KEY_FEE_VARIATION_IN_TINYBAR = 50_000;
    // For some edge cases of custom fee charging,. when crypto transfer fails there are variations in fees
    // Also when auto-creation fails, transaction fee is not re-claimed from payer, so mono-service records
    // has a lot of fees
    private static final long CUSTOM_FEE_ASSESSMENT_VARIATION_IN_TINYBAR = 1000_000_000;
    private static final ObjectMapper om = new ObjectMapper();

    private static final Set<String> FIELDS_TO_SKIP_IN_FUZZY_MATCH = Set.of(
            // These time-dependent fields will necessarily vary each test execution
            "expiry",
            "expirationTime",
            "consensusTimestamp",
            "parent_consensus_timestamp",
            "transactionValidStart",
            // It would be technically possible but quite difficult to fuzzy-match variation here
            "alias",
            "evm_address",
            // And transaction hashes as well
            "transactionHash",
            // Keys are also regenerated every test execution
            "ed25519",
            "ECDSA_secp256k1",
            // Ethereum data depends on ECDSA keys
            "ethereum_data",
            "ethereum_hash",
            // Plus some other fields that we might prefer to make deterministic
            "symbol",
            // Bloom field in ContractCall result
            "bloom",
            // runningHash in SubmitMessageHandler
            "topicRunningHash",
            "prng_bytes",
            "tokenNum");

    private static final String PLACEHOLDER_MEMO = "<entity-num-placeholder-creation>";
    private static final String HAPI_TEST_STREAMS_LOC_TPL =
            "hedera-node/test-clients/build/hapi-test/node%d/data/recordStreams/record0.0.%d";
    private static final String TEST_CLIENTS_SNAPSHOT_RESOURCES_LOC = "record-snapshots";
    private static final String PROJECT_ROOT_SNAPSHOT_RESOURCES_LOC = "hedera-node/test-clients/record-snapshots";
    public static final long UNADJUSTED_NUM_CUTOFF = 666_666_666L;

    private final SnapshotMode mode;
    private final Set<SnapshotMatchMode> matchModes;

    /**
     * The placeholder account number that captures how many entities were in state when the snapshot was taken.
     */
    private long placeholderAccountNum;

    private Instant lowerBoundConsensusStartTime;
    /**
     * The location(s) of the record stream to snapshot or fuzzy-match against. The first location containing
     * records will be used. This was added because the @HapiTest record streams were being written unpredictably,
     * with only some (or none!) of the nodes in the 4-node network flushing their record streams.
     */
    private List<String> recordLocs;
    /**
     * The location to read and save snapshots from.
     */
    private String snapshotLoc;
    /**
     * The full name of the spec that generated the record stream; file name for the JSON snapshot.
     */
    private SnapshotFileMeta snapshotFileMeta;
    /**
     * The memo to use in the {@link com.hederahashgraph.api.proto.java.HederaFunctionality#CryptoCreate} that
     * generates the placeholder number.
     */
    private String placeholderMemo;
    /**
     * If in a fuzzy-match mode, the snapshot to fuzzy-match against.
     */
    private RecordSnapshot snapshotToMatchAgainst;

    public static void main(String... args) throws IOException {
        // Helper to review the snapshot saved for a particular HapiSuite-HapiSpec combination
        final var snapshotFileMeta = new SnapshotFileMeta("ERCPrecompile", "getErc721TokenURIFromErc20TokenFails");
        final var maybeSnapshot = suiteSnapshotsFrom(
                        resourceLocOf(PROJECT_ROOT_SNAPSHOT_RESOURCES_LOC, snapshotFileMeta.suiteName()))
                .flatMap(
                        suiteSnapshots -> Optional.ofNullable(suiteSnapshots.getSnapshot(snapshotFileMeta.specName())));
        if (maybeSnapshot.isEmpty()) {
            throw new IllegalStateException("No such snapshot");
        }
        final var snapshot = maybeSnapshot.get();
        writeReadableItemsToTxt(snapshotFileMeta.toString(), snapshot.parsedItems());
    }

    /**
     * Constructs a snapshot operation with the given mode and a unique memo to be used in the
     * {@link com.hederahashgraph.api.proto.java.HederaFunctionality#CryptoCreate} that generates
     * the placeholder number.
     *
     * @param mode the snapshot mode
     */
    public SnapshotModeOp(@NonNull final SnapshotMode mode, @NonNull final SnapshotMatchMode... specialMatchModes) {
        this.mode = requireNonNull(mode);
        this.matchModes = computeMatchModesIncluding(specialMatchModes);
        // Each snapshot should have a unique placeholder memo so that we can take multiple snapshots
        // without clearing the record streams directory in between
        placeholderMemo = PLACEHOLDER_MEMO + Instant.now();
    }

    /**
     * Initializes the operation by setting its mutable internal fields, most notably the "placeholder" entity
     * number that captures how many entities were in state when the snapshot was taken.
     *
     * @param spec the spec to run
     * @return {@code false} since this operation does not need blocking status resolution
     */
    @Override
    protected boolean submitOp(@NonNull final HapiSpec spec) throws Throwable {
        final var isDeterministic = false;
        if (isDeterministic && mode.targetNetworkType() == spec.targetNetworkType()) {
            this.snapshotFileMeta = SnapshotFileMeta.from(spec);
            switch (mode) {
                case TAKE_FROM_HAPI_TEST_STREAMS -> computePlaceholderNum(
                        hapiTestStreamLocs(), TEST_CLIENTS_SNAPSHOT_RESOURCES_LOC, spec);
                case FUZZY_MATCH_AGAINST_HAPI_TEST_STREAMS -> prepToFuzzyMatchAgainstLoc(
                        hapiTestStreamLocs(), TEST_CLIENTS_SNAPSHOT_RESOURCES_LOC, spec);
            }
        }
        return false;
    }

    /**
     * Returns the record snapshot for the given spec name, if one exists.
     *
     * @param spec the spec to load a snapshot for
     * @return the snapshot, if one exists
     */
    static Optional<RecordSnapshot> maybeLoadSnapshotFor(@NonNull final HapiSpec spec) {
        final var snapshotFileMeta = SnapshotFileMeta.from(spec);
        return suiteSnapshotsFrom(resourceLocOf(TEST_CLIENTS_SNAPSHOT_RESOURCES_LOC, snapshotFileMeta.suiteName()))
                .flatMap(
                        suiteSnapshots -> Optional.ofNullable(suiteSnapshots.getSnapshot(snapshotFileMeta.specName())));
    }

    @Override
    public boolean hasWorkToDo() {
        // We leave the snapshot file metadata null in submitOp() if we are running against a
        // target network that doesn't match the SnapshotMode of this operation; or if the
        // HapiSpec is non-deterministic
        return snapshotFileMeta != null;
    }

    @Override
    public void finishLifecycle(@NonNull final HapiSpec spec) {
        if (!hasWorkToDo()) {
            return;
        }
        try {
            StreamFileAccess.RecordStreamData data = StreamFileAccess.RecordStreamData.EMPTY_DATA;
            for (final var recordLoc : recordLocs) {
                try {
                    log.info("Trying to read post-placeholder items from {}", recordLoc);
                    data = STREAM_FILE_ACCESS.readStreamDataFrom(recordLoc, "sidecar", f -> {
                        final var fileConsTime = parseRecordFileConsensusTime(f);
                        return fileConsTime.isAfter(lowerBoundConsensusStartTime)
                                && new File(f).length() > MIN_GZIP_SIZE_IN_BYTES;
                    });
                    log.info("Read {} record files from {}", data.records().size(), recordLoc);
                } catch (Exception ignore) {
                    // We will try the next location, if any
                }
                if (!data.records().isEmpty()) {
                    break;
                }
            }
            final List<ParsedItem> postPlaceholderItems = new ArrayList<>();
            final var allItems = requireNonNull(data).records().stream()
                    .flatMap(recordWithSidecars -> recordWithSidecars.recordFile().getRecordStreamItemsList().stream())
                    .toList();
            // We only want to snapshot or fuzzy-match the records that come after the placeholder creation
            boolean placeholderFound = false;
            // For statuses that only mono-service rejects at ingest, we need to skip fuzzy-matching;
            // unless there is some special case in the spec where mono-service will still use them
            // (primarily because they appear in a contract operation's child records)
            final Set<ResponseCodeEnum> statusesToIgnore =
                    false ? spec.setup().streamlinedIngestChecks() : EnumSet.noneOf(ResponseCodeEnum.class);
            for (final var item : allItems) {
                final var parsedItem = ParsedItem.parse(item);
                if (parsedItem.isSpecialFileChange()) {
                    // Special file changes vary from their previous contents e.g. file update or append to 0.0.121 or
                    // 0.0.111
                    continue;
                }
                final var body = parsedItem.itemBody();
                if (body.hasNodeStakeUpdate()) {
                    // We cannot ever expect to match node stake update export sequencing
                    continue;
                }
                if (statusesToIgnore.contains(parsedItem.status())) {
                    continue;
                }
                if (!placeholderFound) {
                    if (body.getMemo().equals(placeholderMemo)) {
                        final var streamPlaceholderNum = parsedItem
                                .itemRecord()
                                .getReceipt()
                                .getAccountID()
                                .getAccountNum();
                        Assertions.assertEquals(
                                placeholderAccountNum,
                                streamPlaceholderNum,
                                "Found placeholder account num 0.0." + streamPlaceholderNum + "(expected 0.0."
                                        + placeholderAccountNum + " from creation)");
                        placeholderFound = true;
                    }
                } else {
                    postPlaceholderItems.add(parsedItem);
                }
            }
            // Given just these records, either write a snapshot or fuzzy-match against the existing snapshot
            switch (mode) {
                case TAKE_FROM_HAPI_TEST_STREAMS -> writeSnapshotOf(postPlaceholderItems);
                case FUZZY_MATCH_AGAINST_HAPI_TEST_STREAMS -> fuzzyMatchAgainstSnapshot(postPlaceholderItems);
            }
        } catch (IOException e) {
            throw new UncheckedIOException(e);
        }
    }

    /**
     * Given a list of parsed items from the record stream, fuzzy-matches them against the snapshot.
     *
     * @param postPlaceholderItems the list of parsed items from the record stream
     */
    private void fuzzyMatchAgainstSnapshot(@NonNull final List<ParsedItem> postPlaceholderItems) {
        log.info("Now fuzzy-matching {} post-placeholder records against snapshot", postPlaceholderItems.size());
        final var itemsFromSnapshot = snapshotToMatchAgainst.parsedItems();
        final var minItems = Math.min(postPlaceholderItems.size(), itemsFromSnapshot.size());
        final var snapshotPlaceholderNum = snapshotToMatchAgainst.getPlaceholderNum();
        if (postPlaceholderItems.size() != itemsFromSnapshot.size()) {
            log.warn(
                    "Mismatched item counts between snapshot and post-placeholder records - "
                            + "snapshot had {} items, but post-placeholder had {} items",
                    itemsFromSnapshot.size(),
                    postPlaceholderItems.size());
            writeReadableItemsToTxt("expected", itemsFromSnapshot);
            writeReadableItemsToTxt("actual", postPlaceholderItems);
        }
        for (int i = 0; i < minItems; i++) {
            final var fromSnapshot = itemsFromSnapshot.get(i);
            final var fromStream = postPlaceholderItems.get(i);
            final var j = i;
            fuzzyMatch(
                    fromSnapshot.itemBody(),
                    snapshotPlaceholderNum,
                    fromStream.itemBody(),
                    placeholderAccountNum,
                    () -> "Item #" + j + " body mismatch (EXPECTED " + fromSnapshot.itemBody() + " ACTUAL "
                            + fromStream.itemBody() + ")",
                    matchModes);
            fuzzyMatch(
                    fromSnapshot.itemRecord(),
                    snapshotPlaceholderNum,
                    fromStream.itemRecord(),
                    placeholderAccountNum,
                    () -> "Item #" + j + " record mismatch (EXPECTED " + fromSnapshot.itemRecord() + " ACTUAL "
                            + fromStream.itemRecord() + "FOR BODY " + fromStream.itemBody() + ")",
                    matchModes);
        }
        if (postPlaceholderItems.size() != itemsFromSnapshot.size()) {
            Assertions.fail("Instead of " + itemsFromSnapshot.size() + " items, "
                    + (postPlaceholderItems.size())
                    + " were generated");
        }
    }

    /**
     * Given two messages, recursively asserts that they are equal up to certain "fuzziness" in values like timestamps,
     * hashes, and entity ids; since these quantities will vary based on the number of entities in the system and the
     * time at which the test is run.
     *
     * <p>Two {@link GeneratedMessageV3} messages are fuzzy-equal iff they have the same fields, where each un-skipped
     * primitive field matches exactly; each un-skipped {@link GeneratedMessageV3} field fuzzy-matches; and each
     * un-skipped list field consists of fuzzy-equal elements.
     *
     * @param expectedMessage the expected message
     * @param expectedPlaceholderNum the placeholder number for the expected message
     * @param actualMessage the actual message
     * @param actualPlaceholderNum the placeholder number for the actual message
     * @param mismatchContext a supplier of a string that describes the context of the mismatch
     */
    public static void fuzzyMatch(
            @NonNull GeneratedMessageV3 expectedMessage,
            final long expectedPlaceholderNum,
            @NonNull GeneratedMessageV3 actualMessage,
            final long actualPlaceholderNum,
            @NonNull final Supplier<String> mismatchContext,
            @NonNull final Set<SnapshotMatchMode> matchModes) {
        requireNonNull(expectedMessage);
        requireNonNull(actualMessage);
        requireNonNull(mismatchContext);
        final var expectedType = expectedMessage.getClass();
        final var actualType = actualMessage.getClass();
        if (!expectedType.equals(actualType)) {
            Assertions.fail("Mismatched types between expected " + expectedType + " and " + actualType + " - "
                    + mismatchContext.get());
        }
        expectedMessage = normalized(expectedMessage, expectedPlaceholderNum);
        actualMessage = normalized(actualMessage, actualPlaceholderNum);
        // getAllFields() returns a SortedMap so ordering is deterministic here
        final var expectedFields =
                new ArrayList<>(expectedMessage.getAllFields().entrySet());
        final var actualFields = new ArrayList<>(actualMessage.getAllFields().entrySet());
        if (expectedFields.size() != actualFields.size()) {
            Assertions.fail("Mismatched field counts "
                    + " (" + describeFieldCountMismatch(expectedFields, actualFields) + ") " + "between expected "
                    + expectedMessage + " and " + actualMessage + " - " + mismatchContext.get());
        }
        for (int i = 0, n = expectedFields.size(); i < n; i++) {
            final var expectedField = expectedFields.get(i);
            final var actualField = actualFields.get(i);
            final var expectedName = expectedField.getKey().getName();
            final var actualName = actualField.getKey().getName();
            if (!Objects.equals(expectedName, actualName)) {
                Assertions.fail(
                        "Mismatched field names ('" + expectedName + "' vs '" + actualName + "' between expected "
                                + expectedMessage + " and " + actualMessage + " - " + mismatchContext.get());
            }

            if (shouldSkip(expectedName, expectedField.getValue().getClass(), matchModes)) {
                continue;
            }
            matchValues(
                    expectedName,
                    expectedField.getValue(),
                    expectedPlaceholderNum,
                    actualField.getValue(),
                    actualPlaceholderNum,
                    mismatchContext,
                    matchModes);
        }
    }

    // inline initializers
    @SuppressWarnings({"java:S3599", "java:S1171"})
    private static String describeFieldCountMismatch(
            @NonNull final List<Map.Entry<Descriptors.FieldDescriptor, Object>> expectedFields,
            @NonNull final List<Map.Entry<Descriptors.FieldDescriptor, Object>> actualFields) {
        final Set<String> expectedNames = fieldNamesOf(expectedFields);
        final Set<String> actualNames = fieldNamesOf(actualFields);
        final var expectedButNotObservedNames = new HashSet<>(expectedNames) {
            {
                removeAll(actualNames);
            }
        };
        final var observedButNotExpectedNames = new HashSet<>(actualNames) {
            {
                removeAll(expectedNames);
            }
        };
        final var description = new StringBuilder();
        if (!expectedButNotObservedNames.isEmpty()) {
            description.append("expected but not find ").append(expectedButNotObservedNames);
        }
        if (!observedButNotExpectedNames.isEmpty()) {
            if (!description.isEmpty()) {
                description.append(" AND ");
            }
            description.append("found but did not expect ").append(observedButNotExpectedNames);
        }

        return description.toString();
    }

    private static Set<String> fieldNamesOf(
            @NonNull final List<Map.Entry<Descriptors.FieldDescriptor, Object>> fields) {
        return fields.stream()
                .map(Map.Entry::getKey)
                .map(Descriptors.FieldDescriptor::getName)
                .collect(toSet());
    }

    /**
     * Given an expected value which may be a list, either fuzzy-matches all values in the list against the actual
     * value (which must of course also be a list in this case); or fuzzy-matches the expected single value with the
     * actual value.
     *
     * @param fieldName the name of the field being fuzzy-matched
     * @param expectedValue the expected value
     * @param expectedPlaceholderNum the placeholder number for the expected value
     * @param actualValue the actual value
     * @param actualPlaceholderNum the placeholder number for the actual value
     * @param mismatchContext a supplier of a string that describes the context of the mismatch
     */
    private static void matchValues(
            @NonNull final String fieldName,
            @NonNull final Object expectedValue,
            final long expectedPlaceholderNum,
            @NonNull final Object actualValue,
            final long actualPlaceholderNum,
            @NonNull final Supplier<String> mismatchContext,
            @NonNull final Set<SnapshotMatchMode> matchModes) {
        requireNonNull(fieldName);
        requireNonNull(expectedValue);
        requireNonNull(actualValue);
        requireNonNull(mismatchContext);
        if (expectedValue instanceof List<?> expectedList) {
            if (actualValue instanceof List<?> actualList) {
                if (expectedList.size() != actualList.size()) {
                    Assertions.fail("Mismatched list sizes between expected list " + expectedList + " and " + actualList
                            + " - " + mismatchContext.get());
                }
                for (int j = 0, m = expectedList.size(); j < m; j++) {
                    final var expectedElement = expectedList.get(j);
                    final var actualElement = actualList.get(j);
                    // There are no lists of lists in the record stream, so match single values
                    matchSingleValues(
                            expectedElement,
                            expectedPlaceholderNum,
                            actualElement,
                            actualPlaceholderNum,
                            mismatchContext,
                            fieldName,
                            matchModes);
                }
            } else {
                Assertions.fail("Mismatched types between expected list '" + expectedList + "' and "
                        + actualValue.getClass().getSimpleName() + " '" + actualValue + "' - "
                        + mismatchContext.get());
            }
        } else {
            matchSingleValues(
                    expectedValue,
                    expectedPlaceholderNum,
                    actualValue,
                    actualPlaceholderNum,
                    () -> "Matching field '" + fieldName + "' " + mismatchContext.get(),
                    fieldName,
                    matchModes);
        }
    }

    /**
     * Either recursively fuzzy-matches two given {@link GeneratedMessageV3}; or asserts object equality via
     * {@code Assertions#assertEquals()}; or fails immediately if the types are mismatched.
     *
     * @param expected the expected value
     * @param expectedPlaceholderNum the placeholder number for the expected value
     * @param actual the actual value
     * @param actualPlaceholderNum the placeholder number for the actual value
     * @param mismatchContext a supplier of a string that describes the context of the mismatch
     * @param fieldName the name of the field being fuzzy-matched
     */
    private static void matchSingleValues(
            @NonNull final Object expected,
            final long expectedPlaceholderNum,
            @NonNull final Object actual,
            final long actualPlaceholderNum,
            @NonNull final Supplier<String> mismatchContext,
            @NonNull final String fieldName,
            @NonNull final Set<SnapshotMatchMode> matchModes) {
        requireNonNull(expected);
        requireNonNull(actual);
        requireNonNull(mismatchContext);
        if (expected instanceof GeneratedMessageV3 expectedMessage) {
            if (actual instanceof GeneratedMessageV3 actualMessage) {
                fuzzyMatch(
                        expectedMessage,
                        expectedPlaceholderNum,
                        actualMessage,
                        actualPlaceholderNum,
                        mismatchContext,
                        matchModes);
            } else {
                Assertions.fail("Mismatched types between expected message '" + expectedMessage + "' and "
                        + actual.getClass().getSimpleName() + " '" + actual + "' - " + mismatchContext.get());
            }
        } else {
            // Transaction fees can vary by based on the size of the sig map
            final var maxVariation = feeVariation(matchModes);
            if ("transactionFee".equals(fieldName)) {
                Assertions.assertTrue(
                        Math.abs((long) expected - (long) actual) <= maxVariation,
                        "Transaction fees '" + expected + "' and '" + actual
                                + "' varied by more than " + maxVariation + " tinybar - "
                                + mismatchContext.get());
            } else if ("amount".equals(fieldName) && (maxVariation > 1)) {
                Assertions.assertTrue(
                        Math.abs((long) expected - (long) actual) <= maxVariation,
                        "Amount '" + expected + "' and '" + actual
                                + "' varied by more than " + maxVariation + " tinybar - "
                                + mismatchContext.get());
            } else if (("accountNum".equals(fieldName) || "contractNum".equals(fieldName))) {
                Assertions.assertTrue(
                        (long) expected - (long) actual >= 0,
                        "AccountNum '" + expected + "' was not greater than '" + actual + mismatchContext.get());
            } else if ("name".equals(fieldName)) {
                Assertions.assertTrue(expected != null && actual != null, "Token name is null");
            } else {
                Assertions.assertEquals(
                        expected,
                        actual,
                        "Mismatched values, expected '" + expected + "', got '" + actual + "' - "
                                + mismatchContext.get());
            }
        }
    }

    private static long feeVariation(@NonNull final Set<SnapshotMatchMode> matchModes) {
        return 0;
    }

    /**
     * Given a message that possibly represents an entity id (e.g., {@link AccountID}, returns a normalized message
     * that replaces an entity id number above the placeholder number with its "normalized" value.
     *
     * @param message the message to possibly normalize (if it is an entity id)
     * @param placeholderNum the placeholder number to use in normalization
     * @return the original message if not an entity id; or a normalized message if it is
     */
    private static GeneratedMessageV3 normalized(@NonNull final GeneratedMessageV3 message, final long placeholderNum) {
        requireNonNull(message);
        if (message instanceof AccountID accountID) {
            return accountID.toBuilder()
                    .setAccountNum(numOrOffsetBetween(accountID.getAccountNum(), placeholderNum))
                    .build();
        } else if (message instanceof ContractID contractID) {
            return contractID.toBuilder()
                    .setContractNum(numOrOffsetBetween(contractID.getContractNum(), placeholderNum))
                    .build();
        } else if (message instanceof TopicID topicID) {
            return topicID.toBuilder()
                    .setTopicNum(numOrOffsetBetween(topicID.getTopicNum(), placeholderNum))
                    .build();
        } else if (message instanceof TokenID tokenID) {
            return tokenID.toBuilder()
                    .setTokenNum(numOrOffsetBetween(tokenID.getTokenNum(), placeholderNum))
                    .build();
        } else if (message instanceof FileID fileID) {
            return fileID.toBuilder()
                    .setFileNum(numOrOffsetBetween(fileID.getFileNum(), placeholderNum))
                    .build();
        } else if (message instanceof ScheduleID scheduleID) {
            return scheduleID.toBuilder()
                    .setScheduleNum(numOrOffsetBetween(scheduleID.getScheduleNum(), placeholderNum))
                    .build();
        } else {
            return message;
        }
    }

    /**
     * For numbers smaller than a cutoff used to create intentionally missing entity
     * ids; but greater than the placeholder num, returns the number minus the placeholder
     * num.
     *
     * @param num the number to maybe offset
     * @param placeholderNum the placeholder number to use in normalization
     * @return the number or the number minus the placeholder number
     */
    private static long numOrOffsetBetween(final long num, final long placeholderNum) {
        if (num >= UNADJUSTED_NUM_CUTOFF) {
            return num;
        }
        return placeholderNum < num ? num - placeholderNum : num;
    }

    private void writeSnapshotOf(@NonNull final List<ParsedItem> postPlaceholderItems) throws IOException {
        final var outputLoc = resourceLocOf(snapshotLoc, snapshotFileMeta.suiteName());
        log.info("Writing snapshot of {} post-placeholder items to {}", postPlaceholderItems.size(), outputLoc);

        final var suiteSnapshots = suiteSnapshotsFrom(outputLoc).orElseGet(SuiteSnapshots::new);
        final var specSnapshot = RecordSnapshot.from(placeholderAccountNum, postPlaceholderItems);
        // Update the snapshot for this spec
        suiteSnapshots.addSnapshot(snapshotFileMeta.specName(), specSnapshot);
        final var fout = Files.newOutputStream(outputLoc);
        om.writeValue(fout, suiteSnapshots);
    }

    private static Path resourceLocOf(@NonNull final String snapshotLoc, @NonNull String suiteName) {
        // If we start a test with Ethereum context we are adding a "_Eth" suffix to test name.
        // Before we start a test we need to remove this suffix to get the correct snapshot file name.
        if (suiteName.endsWith(HapiSuite.ETH_SUFFIX)) {
            suiteName = suiteName.replace(HapiSuite.ETH_SUFFIX, "");
        }
        return Paths.get(snapshotLoc, suiteName + ".json");
    }

    private void prepToFuzzyMatchAgainstLoc(
            @NonNull final List<String> recordsLocs, @NonNull final String snapshotLoc, @NonNull final HapiSpec spec) {
        computePlaceholderNum(recordsLocs, snapshotLoc, spec);
        final var suiteSnapshotsPath = resourceLocOf(snapshotLoc, snapshotFileMeta.suiteName());
        final var suiteSnapshots = suiteSnapshotsFrom(suiteSnapshotsPath)
                .orElseThrow(() ->
                        new IllegalStateException("No snapshots found for suite " + snapshotFileMeta.suiteName()));
        snapshotToMatchAgainst = requireNonNull(
                suiteSnapshots.getSnapshot(snapshotFileMeta.specName()),
                "No snapshot found for spec " + snapshotFileMeta.specName());
        log.info(
                "Read {} post-placeholder records from snapshot",
                snapshotToMatchAgainst.getEncodedItems().size());
    }

    /**
     * Given a path, tries to read a {@link SuiteSnapshots} from it.
     *
     * @param p the path to read from
     * @return the suite snapshots, if any
     */
    private static Optional<SuiteSnapshots> suiteSnapshotsFrom(@NonNull final Path p) {
        log.info("Trying to load suite snapshots from {}", p);
        final var f = p.toFile();
        if (f.exists()) {
            try {
                return Optional.of(om.readValue(f, SuiteSnapshots.class));
            } catch (IOException e) {
                log.warn("Could not read existing snapshots", e);
            }
        }
        return Optional.empty();
    }

    private void computePlaceholderNum(
            @NonNull final List<String> recordLocs, @NonNull final String snapshotLoc, @NonNull final HapiSpec spec) {
        this.recordLocs = recordLocs;
        this.snapshotLoc = snapshotLoc;
        // We will get the record's consensus time to set a lower bound on how early we need to
        // look in the record stream for matching items
        final var txn = snapshotFileMeta.toString() + Instant.now();
        final var placeholderCreation = cryptoCreate("PLACEHOLDER")
                .memo(placeholderMemo)
                .via(txn)
                .exposingCreatedIdTo(id -> this.placeholderAccountNum = id.getAccountNum())
                .noLogging();
        final var consTimeLookup = getTxnRecord(txn)
                .exposingTo(creationRecord ->
                        // There is no reason to read a record file whose first consensus time
                        // is more than 2 seconds before we created the placeholder account
                        this.lowerBoundConsensusStartTime = asInstant(creationRecord.getConsensusTimestamp())
                                .minusSeconds(2));
        allRunFor(spec, placeholderCreation, consTimeLookup);
    }

    private List<String> hapiTestStreamLocs() {
        final List<String> locs = new ArrayList<>(SharedNetworkLauncherSessionListener.CLASSIC_HAPI_TEST_NETWORK_SIZE);
        for (int i = 0; i < SharedNetworkLauncherSessionListener.CLASSIC_HAPI_TEST_NETWORK_SIZE; i++) {
            locs.add(String.format(HAPI_TEST_STREAMS_LOC_TPL, i, i + 3));
        }
        return locs;
    }

    private static boolean shouldSkip(
            @NonNull final String expectedName,
            @NonNull final Class<?> expectedType,
            @NonNull final Set<SnapshotMatchMode> matchModes) {
        requireNonNull(expectedName);
        requireNonNull(expectedType);
        requireNonNull(matchModes);
        return false;
    }

    private static void writeReadableItemsToTxt(@NonNull final String name, @NonNull final List<ParsedItem> items) {
        try (final var fout = Files.newBufferedWriter(Paths.get(name + ".txt"))) {
            for (int i = 0, n = items.size(); i < n; i++) {
                final var item = items.get(i);
                fout.write("--- Item #" + i + " ---\n");
                fout.write(item.itemBody() + "\n\n");
                fout.write("➡️\n\n");
                fout.write(item.itemRecord() + "\n\n");
            }
        } catch (IOException e) {
            log.error("Could not write readable items to txt", e);
            throw new UncheckedIOException(e);
        }
    }

    private Set<SnapshotMatchMode> computeMatchModesIncluding(@NonNull final SnapshotMatchMode... specialMatchModes) {
        final Set<SnapshotMatchMode> modes = new HashSet<>(Arrays.asList(specialMatchModes));
        if (System.getenv("CI") != null) {}
        return modes.isEmpty() ? EnumSet.noneOf(SnapshotMatchMode.class) : EnumSet.copyOf(modes);
    }
}
