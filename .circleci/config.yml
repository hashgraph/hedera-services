version: 2.1

commands:
  install-tools:
    description: Install tools for JRS regression
    steps:
      - run:
          name: Install necessary tools
          command: |
            sudo apt update -y;
            sudo apt install -y net-tools;
            sudo apt-get install -y apt-utils;
            sudo apt install -y curl;
            sudo apt install -y python3.7;
            sudo rm /usr/bin/python3;
            sudo ln -s python3.7 /usr/bin/python3;
            sudo apt install -y python3-pip;
            pip3 install --upgrade pip;
            pip3 -q install matplotlib;
            sudo apt-get install -y python3-setuptools;
            pip3 install awscli;
      - run:
          name: Install gcloud cli
          command: |
            apt-get update || apt-get update;
            curl https://sdk.cloud.google.com > install.sh;
            bash install.sh --disable-prompts;
      - run:
          name: Authenticate gcloud cli
          command: |
            echo 'export PATH=/root/google-cloud-sdk/bin:$PATH' >> /root/.bashrc;
            source /root/.bashrc; source /root/google-cloud-sdk/completion.bash.inc;
            source /root/google-cloud-sdk/path.bash.inc;
            echo $GCLOUD_SERVICE_KEY > /tmp/gcloud-service-key.json;
            gcloud auth activate-service-account --key-file=/tmp/gcloud-service-key.json;
            gcloud --quiet config set project ${GOOGLE_PROJECT_ID};
            gcloud --quiet config set compute/zone ${GOOGLE_COMPUTE_ZONE};

  ensure-env-vars:
    description: Ensure the builtin CircleCI env vars are available
    steps:
      - run:
          name: Ensure the builtin CircleCI env vars are available
          command: |
            /repo/.circleci/scripts/ensure-builtin-env-vars.sh

  send-report-to-slack:
    parameters:
      workflow-name:
        description: name of the workflow
        type: string
        default: "continuous integration"
      slack-channel:
        description: name of the slack channel to send report to
        type: string
        default: "hedera-cicd"
      status:
        description: status of the workflow
        type: string
        default: "Passed"
    steps:
      - run:
          name: Send a successful report to slack
          command: |
            /repo/.circleci/scripts/prepare-slack-message.sh \
                "<< parameters.workflow-name >>"
            echo "<< parameters.status >>"  >> /repo/diagnostics/slack_msg.txt
            /repo/.circleci/scripts/call-svcs-app-slack.sh \
                -c << parameters.slack-channel >> \
                -t /repo/diagnostics/slack_msg.txt \
                -s << parameters.status >>


  validate-feature-update-test-report:
    description: Validate feature update test result
    parameters:
      slack-channel:
        description: slack channel to publish to
        type: string
        default: 'hedera-cicd'
      status:
        description: test finishing status
        type: string
        default: 'Passed'
      workflow-name:
        description: test finishing status
        type: string
        default: 'none-workflow'

    steps:
      - run:
          name: Final summary of workflow
          command: |
            /repo/.circleci/scripts/final-summary.sh \
                << parameters.workflow-name >>

      - run:
          name: 'send feature update test result to slack'
          command: |
            /repo/.circleci/scripts/call-svcs-app-slack.sh \
                -c << parameters.slack-channel >> \
                -t /repo/client-logs/feature-update-regression-report.txt \
                -s << parameters.status >>

  validate-record-streams:
    description: Download and validate the record streaming data
    parameters:
      perf-run:
        description: If in perf run, the output handling needs to be tolerant of small portion of censensus time out cases.
        type: boolean
        default: false
    steps:
      - download-record-streams
      - run-record-stream-validator

  download-record-streams:
    description: Fetch the record files and sigs
    steps:
      - run:
          name: Fetch record stream data from testnet nodes
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
              '/repo/.circleci/scripts/download_record_stream_data.sh'
  run-record-stream-validator:
    description: Check the record file sigs and running hashes
    parameters:
      perf-run:
        description: If in perf run, the output handling needs to be tolerant of small portion of censensus time out cases.
        type: boolean
        default: false
    steps:
      - run-eet-suites:
          dsl-args: "RecordStreamValidation"
          ci-properties-map: "recordStreamsDir=/repo/recordstreams"

# insight py is removed from services repo and is stages in platform regression repo.
# we no longer use this job for publishing stats.
  publish-platform-stats:
    description: Generate the insight.py PDF and publish it (e.g. to Slack)
    parameters:
      source-desc:
        type: string
        description: Human-readable summary of the source of these stats
        default: 'a variety of test scenarios'
      append-to-last-stats:
        type: string
        description: Append to last-downloaded stats b/c node restarted
        default: 'false'
      publish-to-slack:
        description: publish to slack channel
        type: boolean
        default: true
      workflow-name:
        type: string
        description: which workflow results to report
        default: 'nightly-regression'

    steps:
      - run:
          name: Fetch stats from spot nodes
          command: |
              /repo/.circleci/scripts/collect-node-stats.sh \
                '<< parameters.append-to-last-stats >>'
      - when:
          condition: << parameters.publish-to-slack >>
          steps:
            - run:
                name: Final summary of workflow
                command: |
                  /repo/.circleci/scripts/final-summary.sh \
                      << parameters.workflow-name >>
            - run:
                name: Generate the insight.py PDF
                command: |
                  /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                     '/repo/.circleci/scripts/gen-stat-insight-pdf.sh'
            - run:
                name: 'Upload the PDF to Slack #hedera-regression channel'
                command: |
                  /repo/.circleci/scripts/publish-stats-pdf-to-slack.sh \
                     "<< parameters.source-desc >>"
  svc-app-slack-msg:
    description: Send a message to Slack via the Services Regression app
    parameters:
      text:
        description: Some literal content to send to Slack.
        type: string
      github-user:
        description: A GitHub user to mention
        type: string
        default: 'nobody-in-particular'
      channel:
        description: A channel ID to target.
        type: string
        default: hedera-regression
      readable:
        description: Human-readable channel description.
        type: string
        default: 'hedera-regression'
    steps:
      - run:
          name: Create a tmp file with the message text.
          command: |
            echo '<< parameters.text >>' > /repo/msg.txt
      - run:
          name: "Say '<< parameters.text >>' to #<< parameters.readable >>"
          command: |
            /repo/.circleci/scripts/call-svcs-app-slack.sh \
                -t /repo/msg.txt \
                -c << parameters.channel >> \
                --github-user << parameters.github-user >>
  svc-app-slack-upload:
    description: Upload a file to Slack via the Services Regression app
    parameters:
      file:
        description: Path of file to upload.
        type: string
      channel:
        description: A channel ID to target.
        type: string
        default: CKWHL8R9A
      readable:
        description: Human-readable channel description.
        type: string
        default: 'hedera-regression'
    steps:
      - run:
          name: "Upload << parameters.file >> to #<< parameters.readable >>"
          command: |
            /repo/.circleci/scripts/call-svcs-app-slack.sh \
                -f << parameters.file >> \
                -c << parameters.channel >>
  cleanup-client-log-storage:
    description: Cleanup test client log storage
    parameters:
      workflow-name:
        description: The current workflow tag
        type: string
        default: 'none-workflow'
    steps:
      - run:
          name: Cleanup old test client log storage
          command: |
            /repo/.circleci/scripts/cleanup-testclient-logs.sh \
               << parameters.workflow-name >>

  save-this-job-client-logs:
    description: Save this client side log files for this job
    parameters:
      workflow-name:
        description: The current workflow name
        type: string
        default: 'none-workflow'
    steps:
      - run:
          name: Save the client side log files for this job
          command: |
            /repo/.circleci/scripts/save-default-client-logs.sh \
               << parameters.workflow-name >>

  fetch-testnet-control-assets:
    description: Add SSH keys, HCL scripts, Ansible playbooks to start testnet
    parameters:
      infra-branch:
        description: Which branch of infrastructure repo to use
        type: string
        default: 'master'
      infra-sha1:
        description: Which commit sha1 of infrastructure repo to use
        type: string
        default: 'HEAD'
    steps:
      - attach_workspace:
          at: /
      - add_ssh_keys:
          fingerprints:
            - "cf:b2:68:a6:65:3f:98:d2:78:18:45:96:b4:fa:b9:1d"
            - "e7:a6:3e:34:3e:d8:fe:64:2c:7f:b6:57:45:03:44:ac"
            - "e7:fd:e2:48:9c:a1:b7:40:95:03:ab:a4:a5:5c:34:21"
      - run:
          name: Checkout infrastructure repo
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
              '/repo/.circleci/scripts/clone-infra-repo.sh << parameters.infra-branch >> \
                  << parameters.infra-sha1 >>'
  provision-testnet-hosts:
    description: Provision hosts using Terraform
    parameters:
      num-hosts:
        description: Number of hosts to provision
        type: integer
        default: 4
      liveness-timeout-secs:
        description: Secs to wait for hosts to become available on port 22
        type: integer
        default: 60
      var-file:
        description: Terraform vars to use
        type: string
      var-region:
        description: Configurable region to override pre-defined in terraform config file.
        type: string
        default: 'us-east-1'
      var-ami-id:
        description: ami-id to override pre-defined. Need to be used together with var-region
        type: string
        default: \"\"
    steps:
      - run:
          name: Create Terraform workspace with << parameters.num-hosts >> hosts
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/create-tf-workspace.sh \
                    << parameters.num-hosts >> \
                    << parameters.liveness-timeout-secs >> \
                    << parameters.var-file >> \
                    << parameters.var-region >> \
                    << parameters.var-ami-id >> '
  pause:
    description: Pause for a given number of seconds
    parameters:
      forSecs:
        type: integer
      reason:
        type: string
        default: ''
    steps:
      - run:
          name: Sleep for << parameters.forSecs >> secs << parameters.reason >>
          command: sleep << parameters.forSecs >>

  prepare-testnet-hosts:
    description: Pickup an existing test net created by terraform through environment varible. No need to pass parameters here.
    steps:
      - run:
          name: Prepare an existing testnet
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
               '/repo/.circleci/scripts/prepare-testnet.sh'
  deploy-testnet-nodes:
    description: Deploy testnet nodes using Ansible
    parameters:
      liveness-timeout-secs:
        description: Secs to wait for nodes to be reachable
        type: integer
      use-hugepage:
        description: let ansible to deploy in hugepage mode
        type: string
        default: 'false'
    steps:
      - run:
          name: Deploy testnet via Ansible
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/deploy-testnet.sh \
                     << parameters.liveness-timeout-secs >> << parameters.use-hugepage >>'
  ensure-testnet-for-reruns:
    description: Ensure reruns from failed jobs have a testnet
    steps:
      - run:
          name: Create a job-scoped testnet if none is available
          command: |
            /repo/.circleci/scripts/start-job-scoped-testnet-if-req.sh
      - run:
          name: Import certificates to Java cacerts keystore
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
               '/repo/.circleci/scripts/import-certificates-to-java-cacerts-keystore.sh'
  cleanup-rerun-testnet-if-present:
    description: Cleanup any testnet created for a rerun job
    steps:
      - run:
          name: Teardown the job-scoped testnet if present
          command: |
            /repo/.circleci/scripts/stop-job-scoped-testnet-if-req.sh
  start-testnet:
    description: Create or use a testnet for the HAPI clients to exercise
    parameters:
      use-existing-network:
        description: tell Circleci to use pre-provisioned testnet instead of creating new a new one.
        type: boolean
        default: false
      var-file:
        description: Terraform vars to use
        type: string
        default: "ci.tfvars"
      infra-branch:
        description: Infrastructure branch to use
        type: string
        default: "hashgraph-hedera-services"
      use-hugepage:
        description: Tell ansible to use hugepage mode when deploying
        type: boolean
        default: false
    steps:
      - fetch-testnet-control-assets:
          infra-branch: << parameters.infra-branch >>
      - unless:
          condition: << parameters.use-existing-network >>
          steps:
            - run: echo "Need to create new spot test net"
            - provision-testnet-hosts:
                liveness-timeout-secs: 120
                var-file: '<< parameters.var-file >>'
                var-region: "us-east-1"
      - when:
          condition: << parameters.use-existing-network >>
          steps:
            - run: echo "Use existing network..."
            - prepare-testnet-hosts
      - run:
          name: Generate self signed certificates for nodes
          command: |
            /repo/.circleci/scripts/generate-self-signed-certificates.sh | \
              tee -a /repo/test-clients/output/hapi-client.log
      - unless:
          condition: << parameters.use-hugepage >>
          steps:
            - deploy-testnet-nodes:
                liveness-timeout-secs: 120
      - when:
          condition: << parameters.use-hugepage >>
          steps:
            - run: echo "Use hugepage mode..."
            - deploy-testnet-nodes:
                liveness-timeout-secs: 120
                use-hugepage: 'true'
      - pause:
          forSecs: 30
      - run:
          name: Disallow any postgres upgrade by apt
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/disallow-postgres-upgrade.sh'
      - run:
          name: Check logs to see if nodes are brought up with TLS GRPC servers
          command: |
            /repo/.circleci/scripts/show_logs.sh
      - run:
          name: Test TLS connections
          command: |
            /repo/.circleci/scripts/test-tls-connections.sh \
              | tee -a /repo/test-clients/output/hapi-client.log
      - persist_to_workspace:
          root: /
          paths:
            - repo/.circleci
            - repo/certificates
            - infrastructure
  postgres-status:
    description: Summarize PostgreSQL status on the nodes
    steps:
      - run:
          name: Summarize postgres status
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/check-postgres-status.sh'
  postgres-get-counts:
    description: Get the number of binary objects in the database
    steps:
      - run:
          name: Get Binary Object Counts
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/postgres-get-counts.sh'
  postgres-verify-counts:
    description: Verify the number of binary objects in the database
    parameters:
      expected-difference:
        description: Expected difference in number of binary objects
        type: integer
    steps:
      - run:
          name: Verify Binary Object Counts
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/postgres-verify-counts.sh \
                    << parameters.expected-difference >>'
  reboot-testnet:
    description: Reboot testnet nodes using Ansible
    parameters:
      liveness-timeout-secs:
        description: Secs to wait for nodes to be reachable
        type: integer
    steps:
      - run:
          name: Reboot testnet via Ansible
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/reboot-testnet.sh'
  cleanup-testnet:
    description: Cleanup Terraform resources for the testnet
    parameters:
      var-file:
        description: Terraform vars to use
        type: string
        default: "ci.tfvars"
    steps:
      - run:
          name: Process Terraform workspace at the end
          command: |
            /repo/.circleci/scripts/destroy-tf-workspace.sh \
                '<< parameters.var-file >>'
  check-logs-for-catastrophe:
    description: Scan the logs for any catastrophic failures in Services
    parameters:
      catastrophe-pattern-sh:
        description: Command returning the Services catastrophe pattern
        type: string
        default: /repo/.circleci/scripts/get-catastrophe-pattern.sh
    steps:
      - run:
          name: Scan logs for catastrophic failures
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/scan-logs-for-catastrophes.sh \
                    << parameters.catastrophe-pattern-sh >>'
  check-logs-for-iss:
    description: Scan the logs for any invalid state signatures
    parameters:
      iss-pattern-sh:
        description: A bash command returning the ISS pattern
        type: string
        default: /repo/.circleci/scripts/get-iss-pattern.sh
    steps:
      - run:
          name: Scan logs for ISS
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/scan-logs-for-iss.sh \
                    << parameters.iss-pattern-sh >>'

  run-jrs-experiment:
    description: Run JRS experiment json
    parameters:
      experiment-name:
        type: string
        default: ""
    steps:
      - run:
          name: Run experiment << parameters.experiment-name >>
          no_output_timeout: 30m
          command: |
            cd /swirlds-platform/regression;
            source /root/.bashrc; source /root/google-cloud-sdk/completion.bash.inc; source /root/google-cloud-sdk/path.bash.inc;
            ./regression_services_circleci.sh configs/services/suites/daily/<< parameters.experiment-name >> /repo

  run-eet-suites:
    description: Run end-to-end tests
    parameters:
      node-terraform-index:
        description: Index into array of Terraform-provisioned hosts
        type: integer
        default: 0
      node-account:
        description: Seq num of the Hedera account id for specified node.
        type: integer
        default: 3
      dsl-args:
        description: Args for the EET suite runner main method
        type: string
      ci-properties-map:
        description: Key=value pairs to configure suite behavior
        type: string
        default: ''
      perf-run:
        description: If in perf run, the output handling needs to be tolerant of small portion of censensus time out cases.
        type: boolean
        default: false
    steps:
      - postgres-status
      - unless:
          condition: << parameters.perf-run >>
          steps:
            - run:
                name: Run end-to-end tests '<< parameters.dsl-args >>'
                command: |
                  CI_PROPERTIES_MAP="<< parameters.ci-properties-map >>" \
                  DSL_SUITE_RUNNER_ARGS="<< parameters.dsl-args >>" \
                  /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                      '/repo/.circleci/scripts/run-scenario-test.sh \
                          com.hedera.services.bdd.suites.SuiteRunner \
                          << parameters.node-terraform-index >> \
                          << parameters.node-account >>'
                no_output_timeout: 60m

      - when:
          condition: << parameters.perf-run >>
          steps:
            - run:
                name: Run end-to-end tests '<< parameters.dsl-args >>'
                command: |
                  CI_PROPERTIES_MAP="<< parameters.ci-properties-map >>" \
                  DSL_SUITE_RUNNER_ARGS="<< parameters.dsl-args >>" \
                  /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                      '/repo/.circleci/scripts/run-umbrella-redux.sh \
                          com.hedera.services.bdd.suites.SuiteRunner \
                          << parameters.node-terraform-index >> \
                          << parameters.node-account >>'
                no_output_timeout: 60m
      - check-logs-for-iss
  run-property-driven-scenario-test:
    description: |
      Run a self-validating HAPI API scenario that takes non-standard args and
      gets all its host information from the various properties files.
    parameters:
      fqcn:
        description: Fully qualified class name of self-validating test.
        type: string
      args:
        description: Command line args to use.
        type: string
        default: ''
    steps:
      - postgres-status
      - run:
          name: Run self-validating HAPI scenario '<< parameters.fqcn >>'
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/run-property-driven-scenario-test.sh \
                    << parameters.fqcn >> \
                    << parameters.args >>'
      - check-logs-for-iss
  run-scenario-test:
    description: Run a self-validating HAPI API test scenario.
    parameters:
      fqcn:
        description: Fully qualified class name of self-validating test.
        type: string
      node-terraform-index:
        description: Index into array of Terraform-provisioned hosts.
        type: integer
        default: 0
      node-account:
        description: Seq num of the Hedera account id for specified node.
        type: integer
        default: 3
      other-args:
        description: Any other args consumed by the scenario main method.
        type: string
        default: ''
    steps:
      - postgres-status
      - run:
          name: Run self-validating HAPI scenario '<< parameters.fqcn >>'
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/run-scenario-test.sh \
                    << parameters.fqcn >> \
                    << parameters.node-terraform-index >> \
                    << parameters.node-account >> \
                    << parameters.other-args >>'
      - check-logs-for-iss
  wait-til-logs-contain:
    description: Wait up to timeout for all host logs to (repeat) a log pattern
    parameters:
      log:
        description: Which log should contain the pattern
        type: string
      pattern-sh:
        description: A bash command returning the pattern to-be-present
        type: string
      pattern-desc:
        description: Human-readable description of the pattern
        type: string
      times:
        description: How many repetitions of the pattern should occur
        type: integer
        default: 1
      timeout-secs:
        description: Timeout for repetitions to be present on all hosts
        type: integer
      sleep-secs:
        description: How long to wait between re-checking for pattern occurrences
        type: integer
    steps:
      - run:
          name: Require << parameters.times >> appearances of << parameters.pattern-desc >> in the << parameters.log >> of all hosts within << parameters.timeout-secs >> secs
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/wait-til-logs-contain.sh \
                    << parameters.log >> \
                    "<< parameters.pattern-sh >>" \
                    << parameters.times >> \
                    << parameters.timeout-secs >> \
                    << parameters.sleep-secs >>'
  start-freeze:
    description: Freeze the nodes for a short time
    parameters:
      node-terraform-index:
        description: Index into array of Terraform-provisioned hosts.
        type: integer
        default: 0
      node-account:
        description: Seq num of the Hedera account id for specified node.
        type: integer
        default: 3
      failure-log-pattern-sh:
        description: Pattern used to detect a scenario failure in the freeze logs
        type: string
    steps:
      - postgres-status
      - run:
          name: Run 'freeze' test with log-based validation
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/run-freeze-test.sh \
                    << parameters.node-terraform-index >> \
                    << parameters.node-account >> \
                    << parameters.failure-log-pattern-sh >>'
      - check-logs-for-iss
  validate-thaw:
    description: Complete validation that the nodes were frozen and now thawed
    parameters:
      freeze-start-timeout-secs:
        description: How long til the logs must all have the freeze pattern
        type: integer
        default: 90
      freeze-pattern-count:
        description: How many repetitions of the freeze pattern should occur
        type: integer
        default: 1
    steps:
      - wait-til-logs-contain:
          log: hgcaa.log
          pattern-sh: /repo/.circleci/scripts/get-freeze-pattern.sh
          pattern-desc: freeze pattern
          times: << parameters.freeze-pattern-count >>
          timeout-secs: << parameters.freeze-start-timeout-secs >>
          sleep-secs: 7
      - run:
          name: Validate freeze began in expected window
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/validate-freeze-start.sh'
      - wait-til-logs-contain:
          log: hgcaa.log
          pattern-sh: /repo/.circleci/scripts/get-thaw-message.sh
          pattern-desc: thaw pattern
          times: 1
          timeout-secs: 180
          sleep-secs: 29
  run-umbrella-test:
    description: Run the so-called 'umbrella' load/longevity test
    parameters:
      config-file:
        description: Properties file to use under test-clients/config/
        type: string
        default: 'umbrellaTest.properties'
      node-terraform-index:
        description: Index into array of Terraform-provisioned hosts.
        type: integer
        default: 0
      node-account:
        description: Seq num of the Hedera account id for specified node.
        type: integer
        default: 3
      expect-unavailable-nodes:
        type: boolean
        description: Flag for whether test is running against frozen nodes
        default: false
    steps:
      - postgres-status
      - run:
          name: Run umbrella test with << parameters.config-file >> <<# parameters.expect-unavailable-nodes >>(PLATFROM should be INACTIVE due to freeze)<</ parameters.expect-unavailable-nodes >>
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/run-umbrella-test.sh \
                    << parameters.config-file >> \
                    << parameters.node-terraform-index >> \
                    << parameters.node-account >> \
                    << parameters.expect-unavailable-nodes >>'
          no_output_timeout: 90m
      - check-logs-for-iss
  restart-with-validations:
    description: Restart the testnet, validate node logs
    parameters:
      active-status-timeout-secs:
        description: How long til nodes must come active
        type: integer
        default: 30
      valid-ss-timeout-secs:
        description: How long til nodes must confirm a valid signed state
        type: integer
        default: 120
      liveness-pattern-count:
        description: How many repetitions of the liveness pattern should occur
        type: integer
        default: 3
      signed-state-pattern-count:
        description: How many repetitions of the signed state pattern should occur
        type: integer
        default: 1
    steps:
      - postgres-status
      - reboot-testnet:
          liveness-timeout-secs: 60
      - pause:
          forSecs: 30
      - wait-til-logs-contain:
          log: hgcaa*.log
          pattern-sh: /repo/.circleci/scripts/get-liveness-pattern.sh
          pattern-desc: alive pattern
          times: << parameters.liveness-pattern-count >>
          timeout-secs: << parameters.active-status-timeout-secs >>
          sleep-secs: 7
      - wait-til-logs-contain:
          log: hgcaa*.log
          pattern-sh: /repo/.circleci/scripts/get-signed-state-pattern.sh
          pattern-desc: merkle state restored
          times: << parameters.signed-state-pattern-count >>
          timeout-secs: << parameters.valid-ss-timeout-secs >>
          sleep-secs: 7
      - wait-til-logs-contain:
          log: swirlds.log
          pattern-sh: /repo/.circleci/scripts/get-lateseq-pattern.sh
          pattern-desc: last known sequence numbers after restart pattern
          times: << parameters.signed-state-pattern-count >>
          timeout-secs: 60
          sleep-secs: 7
      - run:
          name: Scan log of node 0.0.3 for restart lateseq
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
                '/repo/.circleci/scripts/await-default-node-lateseq.sh \
                    /repo/.circleci/scripts/get-lateseq-pattern.sh \
                    60 \
                    7'
      - wait-til-logs-contain:
          log: swirlds.log
          pattern-sh: /repo/.circleci/scripts/get-first-lateseq.sh
          pattern-desc: the same lateseq
          times: 1
          timeout-secs: 30
          sleep-secs: 7
      - check-logs-for-iss

  accessory-test-common-steps:
    description: shared steps for accessory tests
    steps:
      - run-eet-suites:
          dsl-args: "CryptoTransferSuite"
      - run-eet-suites:
          dsl-args: "ContractCallLocalSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "ContractCallSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "ChildStorageSpecs -TLS=on"
      - run-eet-suites:
          dsl-args: "BigArraySpec -TLS=on"
      - run-eet-suites:
          dsl-args: "SmartContractInlineAssemblySpec -TLS=on"
      - run-eet-suites:
          dsl-args: "OCTokenSpec -TLS=on"
      - run-eet-suites:
          dsl-args: "CharacterizationSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "SmartContractFailFirstSpec -TLS=on"
      - run-eet-suites:
          dsl-args: "SmartContractSelfDestructSpec -TLS=on"
      - run-eet-suites:
          dsl-args: "CryptoTransferSuite"
      - run-eet-suites:
          dsl-args: "CryptoQueriesStressTests"
      - run-eet-suites:
          dsl-args: "FileQueriesStressTests"
      - run-eet-suites:
          dsl-args: "ConsensusQueriesStressTests"
      - run-eet-suites:
          dsl-args: "ContractQueriesStressTests"
      - run:
          name: Set log level to INFO
          command: /repo/.circleci/scripts/config-log4j-4normal.sh

executors:
  build-executor:
    parameters:
      workflow-name:
        type: string
        default: ""
    docker:
      - image: qnswirlds/java-builder:0.1.3
      - image: postgres:10
        environment:
          POSTGRES_USER: swirlds
          POSTGRES_PASSWORD: password
          POSTGRES_DB: fcfs
    environment:
      MAVEN_OPTS: -Xmx3200m
      IN_CIRCLE_CI: true
      REPO: /repo
      WORKFLOW-NAME: << parameters.workflow-name >>
    working_directory: /repo

  ci-test-executor:
    parameters:
      tf_workspace:
        type: string
        default: ""
      tf_dir:
        type: string
        default: "/infrastructure/terraform/deployments/aws-4-node-spot-net-swirlds"
      use_existing_network:
        type: string
        default: ""
      workflow-name:
        type: string
        default: ""
    docker:
      - image: qnswirlds/java-builder:0.1.3
    environment:
      TF_DIR: << parameters.tf_dir >>
      IN_CIRCLE_CI: true
      USE_EXISTING_NETWORK: <<parameters.use_existing_network>>
      TF_WORKSPACE: << parameters.tf_workspace >>
      REPO: /repo
      INFRASTRUCTURE_REPO: /infrastructure
      WORKFLOW-NAME: << parameters.workflow-name >>
    working_directory: /repo

workflows:
  AWS-Daily-Services-Crypto-Update-5N-1C:
    triggers:
      - schedule:
          cron: "30 4 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-update-node-tests:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Crypto-Update-5N-1C"
          test-name: "AWS-Daily-Services-Crypto-Update-5N-1C.json"

  GCP-Daily-Services-Crypto-Update-5N-1C:
    triggers:
      - schedule:
          cron: "35 4 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-update-node-tests:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Crypto-Update-5N-1C"

  AWS-Weekly-Services-Crypto-Restart-Performance-15N-15C:
    triggers:
      - schedule:
          cron: "0 5 * * 6,0"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - weekly-run-crypto-transfer-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Weekly-Services-Crypto-Restart-Performance-15N-15C"
          test-name: "AWS-Weekly-Services-Crypto-Restart-Performance-15N-15C.json"

  GCP-Weekly-Services-Crypto-Restart-Performance-15N-15C:
    triggers:
      - schedule:
          cron: "5 5 * * 6,0"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - weekly-run-crypto-transfer-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Weekly-Services-Crypto-Restart-Performance-15N-15C"

  AWS-Weekly-Services-HCS-Restart-Performance-15N-15C:
    triggers:
      - schedule:
          cron: "0 10 * * 6,0"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - weekly-run-HCS-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Weekly-Services-HCS-Restart-Performance-15N-15C"
          test-name: "AWS-Daily-Services-Comp-Basic-4N-1C.json"

  GCP-Weekly-Services-HCS-Restart-Performance-15N-15C:
    triggers:
      - schedule:
          cron: "5 10 * * 6,0"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - weekly-run-HCS-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Weekly-Services-HCS-Restart-Performance-15N-15C"

  AWS-Daily-Services-Comp-NetError-4N-1C:
    triggers:
      - schedule:
          cron: "15 5 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-network-error-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Comp-NetError-4N-1C"
          test-name: "AWS-Daily-Services-Comp-NetError-4N-1C.json"

  GCP-Daily-Services-Comp-NetError-4N-1C:
    triggers:
      - schedule:
          cron: "20 5 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-network-error-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Comp-NetError-4N-1C"

# This workflow will be running normally in master branch on a daily basis
  AWS-Daily-Services-Crypto-Migration-4N-1C:
    triggers:
          - schedule:
              cron: "30 5 * * *"
              filters:
                branches:
                  only:
                    - Disable-master
    jobs:
      - build-platform-and-services
      - run-testnet-migration-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Crypto-Migration-4N-1C"
          test-name: "AWS-Daily-Services-Crypto-Migration-4N-1C.json"
  # This workflow will be running normally in master branch on a daily basis

  GCP-Daily-Services-Crypto-Migration-5N-1C:
    triggers:
      - schedule:
          cron: "35 5 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-testnet-migration-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Crypto-Migration-5N-1C"

# The mainnet migration test needs to be run in a 13-node test network.
# Enable this workflow to run on a daily only when a new release branch is tagged and branched.
# Once this branch is released, disable this workflow.
  nightly-mainnet-migration-regression:
    triggers:
          - schedule:
              cron: "0 23,8 * * *"
              filters:
                branches:
                  only:
                    - release-branch-N
    jobs:
      - build-platform-and-services
      - run-mainnet-migration-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "nightly-mainnet-migration-regression"

  AWS-Daily-Services-Crypto-Restart-4N-1C:
    triggers:
      - schedule:
          cron: "0 6 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-software-update-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Crypto-Restart-4N-1C"
          test-name: "AWS-Daily-Services-Crypto-Restart-4N-1C.json"

  GCP-Daily-Services-Crypto-Restart-4N-1C:
    triggers:
      - schedule:
          cron: "5 6 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-software-update-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Crypto-Restart-4N-1C"

  AWS-Daily-Services-Recovery-4N-1C:
    triggers:
      - schedule:
          cron: "30 6 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-state-recover-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Recovery-4N-1C"
          test-name: "AWS-Daily-Services-Recovery-4N-1C.json"

  GCP-Daily-Services-Recovery-4N-1C:
    triggers:
      - schedule:
          cron: "35 6 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-state-recover-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Recovery-4N-1C"

  AWS-Daily-Services-Comp-Basic-Performance-4N-4C:
    triggers:
      - schedule:
          cron: "30 6 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-performance-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Comp-Basic-Performance-4N-4C"
          test-name: "AWS-Daily-Services-Comp-Basic-Performance-4N-4C.json"

  GCP-Daily-Services-Comp-Basic-Performance-4N-4C:
    triggers:
      - schedule:
          cron: "35 6 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-performance-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Comp-Basic-Performance-4N-4C"

  AWS-Daily-Services-Comp-Basic-HCS-Performance-4N-4C:
    triggers:
      - schedule:
          cron: "30 4 * * *"
          filters:
            branches:
              only:
                - Disable-master

    jobs:
      - build-platform-and-services
      - run-performance-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Comp-Basic-HCS-Performance-4N-4C"
          test-name: "AWS-Daily-Services-Comp-Basic-HCS-Performance-4N-4C.json"

  GCP-Daily-Services-Comp-Basic-HCS-Performance-4N-4C:
    triggers:
      - schedule:
          cron: "30 10 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-performance-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Comp-Basic-HCS-Performance-4N-4C"

  AWS-Daily-Services-Comp-Restart-Performance-6N-6C:
    triggers:
      - schedule:
          cron: "30 6 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Comp-Restart-Performance-6N-6C"
          test-name: "AWS-Daily-Services-Comp-Restart-Performance-6N-6C.json"

  GCP-Daily-Services-Comp-Restart-Performance-6N-6C:
    triggers:
      - schedule:
          cron: "35 6 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Comp-Restart-Performance-6N-6C"

  AWS-Daily-Services-Comp-Restart-HTS-Performance-6N-6C:
    triggers:
      - schedule:
          cron: "30 4 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Comp-Restart-HTS-Performance-6N-6C"
          test-name: "AWS-Daily-Services-Comp-Restart-HTS-Performance-6N-6C.json"

  GCP-Daily-Services-Comp-Restart-HTS-Performance-6N-6C:
    triggers:
      - schedule:
          cron: "39 0 * * *"
          filters:
            branches:
              only:
                - master

    jobs:
      - build-platform-and-services
      - run-start-from-saved-state-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Comp-Restart-HTS-Performance-6N-6C"

  AWS-Daily-Services-Comp-Reconnect-4N-1C:
    triggers:
      - schedule:
          cron: "0 7 * * *"
          filters:
            branches:
              only:
                - Disable-master
    jobs:
      - build-platform-and-services
      - run-reconnect-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "AWS-Daily-Services-Comp-Reconnect-4N-1C"
          test-name: "AWS-Daily-Services-Comp-Reconnect-4N-1C.json"

  GCP-Daily-Services-Comp-Reconnect-4N-1C:
    triggers:
      - schedule:
          cron: "5 7 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - build-platform-and-services
      - run-reconnect-regression:
          context: Slack
          requires:
            - build-platform-and-services
          pre-steps:
            - install-tools
            - attach_workspace:
                at: /
          workflow-name: "GCP-Daily-Services-Comp-Reconnect-4N-1C"

  nightly-simulate-network-outage:
    triggers:
        - schedule:
            cron: "0 6 * * *"
            filters:
              branches:
                only:
                  - master
    jobs:
      - fast-build-artifact:
          context: Slack
          workflow-name: "nightly-simulate-network-outage"
      - start-singlejob-testnet:
          context: Slack
          requires:
            - fast-build-artifact
          workflow-name: "nightly-simulate-network-outage"
          infra-branch: services-with-platform070
      - run-accessory-tests:
          context: Slack
          requires:
            - start-singlejob-testnet
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          workflow-name: "nightly-simulate-network-outage"
      - run-network-sim:
          context: Slack
          requires:
            - run-accessory-tests
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          workflow-name: "nightly-simulate-network-outage"
      - rerun-accessory-tests:
          context: Slack
          requires:
            - run-network-sim
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - send-report-to-slack:
                workflow-name: simulate network outage
                status: Passed
            - cleanup-rerun-testnet-if-present
          workflow-name: "nightly-simulate-network-outage"
      - cleanup-singlejob-testnet:
          context: Slack
          requires:
            - rerun-accessory-tests
          pre-steps:
            - attach_workspace:
                at: /

  feature-update-regression:
    triggers:
        - schedule:
            cron: "0 8 * * *"
            filters:
              branches:
                only:
                  - master
    jobs:
      - fast-build-artifact:
          context: Slack
          post-steps:
            - save-this-job-client-logs:
                workflow-name: "feature-update-regression"
          workflow-name: "feature-update-regression"
      - start-singlejob-testnet:
          context: Slack
          requires:
            - fast-build-artifact
          workflow-name: "feature-update-regression"
          infra-branch: services-with-platform070
          post-steps:
            - save-this-job-client-logs:
                workflow-name: "feature-update-regression"
      - run-accessory-tests:
          context: Slack
          requires:
            - start-singlejob-testnet
          post-steps:
            - save-this-job-client-logs:
                workflow-name: "feature-update-regression"
            - cleanup-rerun-testnet-if-present
          workflow-name: "feature-update-regression"
      - run-update-feature:
          context: Slack
          requires:
            - run-accessory-tests
          post-steps:
            - save-this-job-client-logs:
                workflow-name: "feature-update-regression"
            - cleanup-rerun-testnet-if-present
          workflow-name: "feature-update-regression"
      - run-update-jar-files:
          context: Slack
          requires:
            - run-update-feature
          post-steps:
            - save-this-job-client-logs:
                workflow-name: "feature-update-regression"
            - cleanup-rerun-testnet-if-present
          new-marker : "new marker string"
          workflow-name: "feature-update-regression"
      - rerun-accessory-tests:
          context: Slack
          requires:
            - run-update-jar-files
          post-steps:
            - save-this-job-client-logs:
                workflow-name: "feature-update-regression"
            - validate-feature-update-test-report:
                status: "Passed"
                workflow-name: "feature-update-regression"
            - cleanup-rerun-testnet-if-present
          workflow-name: "feature-update-regression"
      - cleanup-singlejob-testnet:
          context: Slack
          requires:
            - rerun-accessory-tests
          pre-steps:
            - attach_workspace:
                at: /

  nightly-freeze-restart:
    triggers:
      - schedule:
          cron: "0 5 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - fast-build-artifact:
          context: Slack
          workflow-name: freeze restart
      - start-singlejob-testnet:
          context: Slack
          requires:
            - fast-build-artifact
          workflow-name: freeze restart
          infra-branch: services-with-platform070
      - run-umbrella-freeze-restart-test:
          context: Slack
          name: freeze-restart-first-round
          requires:
            - start-singlejob-testnet
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          freeze-pattern-count: 1
          liveness-pattern-count: 3
          signed-state-pattern-count: 1
          workflow-name: freeze restart
      - run-umbrella-freeze-restart-test:
          context: Slack
          name: freeze-restart-second-round
          requires:
            - freeze-restart-first-round
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          freeze-pattern-count: 2
          liveness-pattern-count: 5
          signed-state-pattern-count: 2
          workflow-name: freeze restart
      - run-umbrella-freeze-restart-test:
          context: Slack
          name: freeze-restart-third-round
          requires:
            - freeze-restart-second-round
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - publish-platform-stats:
                source-desc: freeze restart
            - cleanup-rerun-testnet-if-present
          freeze-pattern-count: 3
          liveness-pattern-count: 7
          signed-state-pattern-count: 3
          workflow-name: freeze restart
      - cleanup-singlejob-testnet:
          context: Slack
          requires:
            - freeze-restart-third-round
          pre-steps:
            - attach_workspace:
                at: /

  daily-aws-summary:
    triggers:
      - schedule:
          cron: "15 14 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - aws-summary:
          context: Slack

  nightly-comprehensive-functional-regression:
    triggers:
      - schedule:
          cron: "15 4 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - fast-build-artifact:
          context: Slack
          workflow-name: "nightly-comprehensive-functional-regression"
      - start-singlejob-testnet:
          context: Slack
          requires:
            - fast-build-artifact
          workflow-name: "nightly-comprehensive-functional-regression"
      - run-comprehensive-functional-test:
          context: Slack
          requires:
            - start-singlejob-testnet
          pre-steps:
            - attach_workspace:
                at: /
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          workflow-name: "nightly-comprehensive-functional-regression"

      - cleanup-singlejob-testnet:
          context: Slack
          requires:
            - run-comprehensive-functional-test
          pre-steps:
            - attach_workspace:
                at: /

  continuous-integration-gcp:
      jobs:
        - build-platform-and-services
        - run-continuous-integration-gcp:
            context: Slack
            requires:
              - build-platform-and-services
            pre-steps:
              - install-tools
              - attach_workspace:
                  at: /
            workflow-name: "Continuous Integration GCP"
            filters:
              branches:
                ignore:
                  - /.*-PERF/
                  - /.*-REGRESSION/

  continuous-integration:
    jobs:
      - build-artifact:
          context: SonarCloud
          filters:
            branches:
              ignore:
                - /.*-PERF/
                - /.*-REGRESSION/
          workflow-name: "Continuous integration"
      - start-singlejob-testnet:
          context: Slack
          requires:
            - build-artifact
          workflow-name: "Continuous integration"
          infra-branch: services-with-platform070
      - run-token-scenarios:
          context: Slack
          requires:
            - start-singlejob-testnet
          pre-steps:
            - attach_workspace:
                at: /
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          workflow-name: "Continuous integration"
      - run-file-scenarios:
          context: Slack
          requires:
            - run-token-scenarios
          pre-steps:
            - attach_workspace:
                at: /
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          workflow-name: "Continuous integration"
      - run-consensus-and-crypto-scenarios:
          context: Slack
          requires:
            - run-file-scenarios
          pre-steps:
            - attach_workspace:
                at: /
            - run: /repo/.circleci/scripts/echo-env.sh
            - ensure-testnet-for-reruns
          post-steps:
            - cleanup-rerun-testnet-if-present
          workflow-name: "Continuous integration"
      - run-smart-contract-scenarios:
          context: Slack
          requires:
            - run-consensus-and-crypto-scenarios
          pre-steps:
            - attach_workspace:
                at: /
            - ensure-testnet-for-reruns
          post-steps:
            - send-report-to-slack:
                workflow-name: "Continuous integration"
                status: Passed
            - cleanup-rerun-testnet-if-present
          workflow-name: "Continuous integration"
      - cleanup-singlejob-testnet:
          context: Slack
          requires:
            - run-smart-contract-scenarios
          pre-steps:
            - attach_workspace:
                at: /
jobs:
  start-singlejob-testnet:
    parameters:
      infra-branch:
        description: Infrastructure branch to use
        type: string
        default: "hashgraph-hedera-services"
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - start-testnet:
          infra-branch: << parameters.infra-branch >>
  cleanup-singlejob-testnet:
    executor: ci-test-executor
    steps:
      - cleanup-testnet
  start-multijob-testnet:
    executor: ci-test-executor
    steps:
      - attach_workspace:
          at: /
      - start-testnet:
          var-file: "regression.tfvars"
      - persist_to_workspace:
          root: /
          paths:
            - repo/.circleci
            - infrastructure

  build-artifact:
    parameters:
      sys-props:
        type: string
        description: System properties for mvn install
        default: ''
      mvn-args:
        type: string
        description: Args for mvn install
        default: ''
      workflow-name:
        type: string
        default: ""
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - checkout
      - run:
          name: prepare log dir
          command: |
            mkdir -p /repo/test-clients/output
      - run:
          name: mvn install
          # use double quote otherwise the backslash of line continuation will be treated as part of mvn parameter
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
              "mvn --no-transfer-progress -Dsonar.branch.name=${CIRCLE_BRANCH} -Dsonar.login=${SONAR_TOKEN} clean install sonar:sonar \
              | tee /repo/test-clients/output/hapi-client.log"
      - run:
          name: Save Unit Test Results
          command: |
            set -x
            JUNIT_PATH="${HOME}/junit"

            if [[ ! -d "${JUNIT_PATH}" ]]; then
              mkdir -pv "${JUNIT_PATH}"
            fi
            find . -type f -regex ".*/target/surefire-reports/.*xml" -exec cp -v {} "${JUNIT_PATH}" \;
          when: always
      - store_test_results:
          path: ~/junit
      - store_artifacts:
          path: ~/junit
      - run:
          name: Upload codecov
          command: |
            apt-get update
            apt-get install -y curl
            bash <(wget -O - https://codecov.io/bash)
      - run:
          name: Upload built artifacts to S3 (for Ansible download)
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
               '/repo/.circleci/scripts/package-hapi-artifacts.sh hedera-node/data/lib'
            /repo/.circleci/scripts/trap-failure-report.sh \
               '/repo/.circleci/scripts/upload-dir-to-s3.sh \
                hedera-node/data lib SHA-${CIRCLE_SHA1}'
      - run:
          name: Reposition config for Ansible scripts
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
                'mkdir -p /repo/HapiApp2.0'
            /repo/.circleci/scripts/trap-failure-report.sh \
                'cp /repo/hedera-node/log4j2.xml /repo/HapiApp2.0'
      - persist_to_workspace:
          root: /
          paths:
            - repo/.git
            - repo/.circleci
            - repo/hapiProto
            - repo/test-clients
            - repo/HapiApp2.0
            - root/.m2
            - repo/hedera-node

  fast-build-artifact:
    parameters:
      workflow-name:
        type: string
        default: ""
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - checkout
      - cleanup-client-log-storage:
          workflow-name: << parameters.workflow-name >>
      - run:
          name: prepare log dir
          command: |
            mkdir -p /repo/test-clients/output
      - run:
          name: mvn install
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
               'mvn --no-transfer-progress clean install -DskipTests | tee /repo/test-clients/output/hapi-client.log'
      - run:
          name: Upload built artifacts to S3 (for Ansible download)
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
              '/repo/.circleci/scripts/package-hapi-artifacts.sh \
                     hedera-node/data/lib | tee -a /repo/test-clients/output/hapi-client.log'
            /repo/.circleci/scripts/trap-failure-report.sh \
              '/repo/.circleci/scripts/upload-dir-to-s3.sh \
                     hedera-node/data lib SHA-${CIRCLE_SHA1} | tee -a /repo/test-clients/output/hapi-client.log'
      - run:
          name: Reposition config for Ansible scripts
          command: |
            /repo/.circleci/scripts/trap-failure-report.sh \
               'mkdir -p /repo/HapiApp2.0'
            /repo/.circleci/scripts/trap-failure-report.sh \
               'cp /repo/hedera-node/log4j2.xml /repo/HapiApp2.0'
      - persist_to_workspace:
          root: /
          paths:
            - repo/.git
            - repo/.circleci
            - repo/hapiProto
            - repo/test-clients
            - repo/HapiApp2.0
            - root/.m2
            - repo/hedera-node

  run-update-node-tests:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Crypto-Update-5N-1C.json"
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of update node tests to AWS
          command: |
            cd /swirlds-platform/regression/results/5N_1C/Update/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/5N_1C/Update/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/5N_1C/Update/*

      - store_artifacts:
          path: /results.tar.gz

  run-performance-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Comp-Basic-Performance-4N-4C.json"
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of performance regression to AWS
          command: |
            cd /swirlds-platform/regression/results/4N_4C/Performance/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/4N_4C/Performance/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_4C/Performance/*

      - store_artifacts:
          path: /results.tar.gz

  run-network-error-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Comp-NetError-4N-1C.json"
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of network error regression to AWS
          command: |
            cd /swirlds-platform/regression/results/4N_1C/NetError/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/4N_1C/NetError/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_1C/NetError/*

      - store_artifacts:
          path: /results.tar.gz

  run-testnet-migration-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Crypto-Migration-5N-1C.json"
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run:
          name: Modify Payer account for Public testnet Migration test
          command: |
            echo -n "$KEY_DevTestNetTreasury" > /repo/test-clients/src/main/resource/StartUpAccount.txt;

      - run:
          name: Run Public testnet Migration test
          command: |
            cd /repo ; mvn --no-transfer-progress clean install -DskipTests;
            cd /swirlds-platform/regression;
            source /root/.bashrc; source /root/google-cloud-sdk/completion.bash.inc; source /root/google-cloud-sdk/path.bash.inc;
            ./regression_services_circleci.sh configs/services/suites/daily/<< parameters.test-name >> /repo

      - run:
          name: Sync results of public testnet migration test to AWS
          command: |
            cd /swirlds-platform/regression/results/4N_1C/Migration/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/4N_1C/Migration/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_1C/Migration/*

      - store_artifacts:
          path: /results.tar.gz

  run-mainnet-migration-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run:
          name: Modify Payer account for Mainnet Migration test
          command: |
            sed -i 's/default.payer=0.0.2/default.payer=0.0.950/g' /repo/test-clients/src/main/resource/spec-default.properties;
            echo -n "$KEY_950" > /repo/test-clients/src/main/resource/StartUpAccount.txt;

      - run:
          name: Run Mainnet Migration test
          command: |
            cd /repo ; mvn --no-transfer-progress clean install -DskipTests;
            cd /swirlds-platform/regression;
            ./regression_services_circleci.sh configs/services/daily/13N_13C/AWS-Services-Daily-MainnetMigration-13N-1C.json /repo

      - run:
          name: Sync results of mainnet migration test to AWS
          command: |
            cd /swirlds-platform/regression/results/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/*

      - store_artifacts:
          path: /results.tar.gz

  run-software-update-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Crypto-Restart-4N-1C.json"
    executor:
      name: build-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of software update regression to AWS
          command: |
            cd /swirlds-platform/regression/results/4N_1C/Restart/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/4N_1C/Restart/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_1C/Restart/*

      - store_artifacts:
          path: /results.tar.gz

  run-state-recover-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Recovery-4N-1C.json"
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of state recover regression to AWS
          command: |
            cd /swirlds-platform/regression/results/4N_1C/Recovery/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/4N_1C/Recovery/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_1C/Recovery/*

      - store_artifacts:
          path: /results.tar.gz

  run-start-from-saved-state-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Comp-Restart-Performance-6N-6C.json"
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run:
          name: Modify Payer account for Public testnet start from saved state test
          command: |
            echo -n "$KEY_DevTestNetTreasury" > /repo/test-clients/src/main/resource/StartUpAccount.txt;

      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of software update regression to AWS
          command: |
            cd /swirlds-platform/regression/results/6N_6C/Performance/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/6N_6C/Performance/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/6N_6C/Performance/*

      - store_artifacts:
          path: /results.tar.gz

  run-reconnect-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Daily-Services-Comp-Reconnect-4N-1C.json"
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run-jrs-experiment:
          experiment-name: << parameters.test-name >>

      - run:
          name: Sync results of reconnect regression to AWS
          command: |
            cd /swirlds-platform/regression/results/4N_1C/Reconnect/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/4N_1C/Reconnect/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_1C/Reconnect/*

      - store_artifacts:
          path: /results.tar.gz

  run-continuous-integration-gcp:
    parameters:
      workflow-name:
        type: string
        default: ""
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run:
          name: Run continuous integration tests
          no_output_timeout: 30m
          command: |
            cd /swirlds-platform/regression;
            source /root/.bashrc; source /root/google-cloud-sdk/completion.bash.inc; source /root/google-cloud-sdk/path.bash.inc;
            ./regression_services_circleci.sh configs/services/suites/ci/GCP-Commit-Services-Comp-Basic-4N-1C.json /repo

      - run:
          name: Sync results of continuous integration to circelCI job
          command: |
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/4N_1C/CI/*

      - store_artifacts:
          path: /results.tar.gz

  weekly-run-crypto-transfer-start-from-saved-state-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Weekly-Services-Crypto-Restart-Performance-15N-15C.json"
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run:
          name: Modify Payer account for Public testnet start from saved state test
          command: |
            echo -n "$KEY_DevTestNetTreasury";    echo -n /repo/test-clients/src/main/resource/StartUpAccount.txt;
#            echo -n "$KEY_DevTestNetTreasury" > /repo/test-clients/src/main/resource/StartUpAccount.txt;
      - run:
          name: Run start from saved state regression tests
          no_output_timeout: 120m
          command: |
            cd /swirlds-platform/regression;
            source /root/.bashrc; source /root/google-cloud-sdk/completion.bash.inc; source /root/google-cloud-sdk/path.bash.inc;
            ./regression_services_circleci.sh configs/services/suites/weekly/<< parameters.test-name >> /repo

      - run:
          name: Sync results of software update regression to AWS
          command: |
            cd /swirlds-platform/regression/results/15N_15C/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/15N_15C/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/15N_15C/*

      - store_artifacts:
          path: /results.tar.gz

  weekly-run-HCS-start-from-saved-state-regression:
    parameters:
      workflow-name:
        type: string
        default: ""
      test-name:
        type: string
        default: "GCP-Weekly-Services-HCS-Restart-Performance-15N-15C.json"
    executor:
      name: build-executor
      workflow-name: << parameters.workflow-name >>
    steps:
      - run:
          name: Modify Payer account for Public testnet start from saved state test
          command: |
            echo -n "$KEY_DevTestNetTreasury";    echo -n /repo/test-clients/src/main/resource/StartUpAccount.txt;
#            echo -n "$KEY_DevTestNetTreasury" > /repo/test-clients/src/main/resource/StartUpAccount.txt;
      - run:
          name: Run start from saved state regression tests
          no_output_timeout: 180m
          command: |
            cd /swirlds-platform/regression;
            source /root/.bashrc; source /root/google-cloud-sdk/completion.bash.inc; source /root/google-cloud-sdk/path.bash.inc;
            ./regression_services_circleci.sh configs/services/suites/weekly/<< parameters.test-name >> /repo

      - run:
          name: Sync results of software update regression to AWS
          command: |
            cd /swirlds-platform/regression/results/15N_15C/; find . -type d -name data -prune -exec rm -rf {} \;
            aws s3 sync /swirlds-platform/regression/results/15N_15C/ s3://hedera-service-regression-jrs;
            tar -czvf /results.tar.gz  /swirlds-platform/regression/results/15N_15C/*

      - store_artifacts:
          path: /results.tar.gz

  build-platform-and-services:
    parameters:
      workflow-name:
        type: string
        default: ""
    executor:
      name: build-executor
    steps:
      - attach_workspace:
          at: /
      - add_ssh_keys:
          fingerprints:
            - "96:47:c4:5c:e7:45:06:c5:26:a5:85:ef:41:22:2f:d6"
            - "14:21:e9:81:1f:ae:df:ec:11:60:4a:49:e0:b9:bb:58"
            - "e7:a6:3e:34:3e:d8:fe:64:2c:7f:b6:57:45:03:44:ac"
      - checkout
      - run:
          name: Build hedera-services repo
          command: |
                mvn --no-transfer-progress clean install -DskipTests
      - run:
          name: Checkout swirlds-platform repos and build
          command: |
            sed -i -e 's/Host services-jrs-regression/Host services-jrs-regression\n HostName github.com/g' ~/.ssh/config
            cd /; GIT_SSH_COMMAND="ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" \
            git clone ssh://git@services-jrs-regression/swirlds/swirlds-platform.git;
            cd /swirlds-platform;
            sed -i -e 's/github.com/services-jrs-regression/g' .gitmodules;
            git submodule update --init --recursive --checkout;
            cd regression;
            cd ..;
            mvn --no-transfer-progress clean install -DskipTests;

      - run:
          name: Save PEM file to keys folder
          command: |
            cp ~/.ssh/id_rsa_e7a63e343ed8fe642c7fb657450344ac /swirlds-platform/regression/keys/services-regression.pem

      - persist_to_workspace:
          root: /
          paths:
            - repo/
            - swirlds-platform/

  aws-summary:
    executor: ci-test-executor
    steps:
      - checkout
      - run:
          name: Summarize all AWS instances currently used by regions
          command: |
            /repo/.circleci/scripts/aws-summary.sh

  run-accessory-tests:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - attach_workspace:
          at: /
      - ensure-testnet-for-reruns
      - run:
          name:  Reset client log
          command: |
            cat /dev/null > /repo/test-clients/output/hapi-client.log
      - run: /repo/.circleci/scripts/echo-env.sh
      - accessory-test-common-steps

  rerun-accessory-tests:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - attach_workspace:
          at: /
      - ensure-testnet-for-reruns
      - run:
          name:  Reset client log
          command: |
            cat /dev/null > /repo/test-clients/output/hapi-client.log
      - run: /repo/.circleci/scripts/echo-env.sh
      - accessory-test-common-steps

  run-consensus-and-crypto-scenarios:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-eet-suites:
          dsl-args: "SignedTransactionBytesRecordsSuite"
      - run-eet-suites:
          dsl-args: "TopicCreateSpecs"
      - run-eet-suites:
          dsl-args: "TopicUpdateSpecs -TLS=on"
          node-terraform-index: 1
          node-account: 4
      - run-eet-suites:
          dsl-args: "TopicDeleteSpecs"
      - run-eet-suites:
          dsl-args: "SubmitMessageSpecs"
      - run-eet-suites:
          dsl-args: "HCSTopicFragmentationSuite -TLS=alternate"
      - run-eet-suites:
          dsl-args: "TopicGetInfoSpecs"
      - run-eet-suites:
          dsl-args: "BucketThrottlingSpec"
      - run-eet-suites:
          dsl-args: "ControlAccountsExemptForUpdates"
      - run-eet-suites:
          dsl-args: "CryptoTransferSuite"
      - run-eet-suites:
          dsl-args: "CryptoUpdateSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "CryptoTransferSuite"
      - run-eet-suites:
          dsl-args: "CryptoRecordSanityChecks"
      - run-eet-suites:
          dsl-args: "SuperusersAreNeverThrottled"
      - run-eet-suites:
          dsl-args: "CannotDeleteSystemEntitiesSuite"

  run-token-scenarios:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-eet-suites:
          dsl-args: "TokenAssociationSpecs"
      - run-eet-suites:
          dsl-args: "TokenCreateSpecs"
      - run-eet-suites:
          dsl-args: "TokenUpdateSpecs"
      - run-eet-suites:
          dsl-args: "TokenDeleteSpecs"
      - run-eet-suites:
          dsl-args: "TokenManagementSpecs"
      - run-eet-suites:
          dsl-args: "TokenTransactSpecs"

  run-file-scenarios:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-eet-suites:
          dsl-args: "FileCreateSuite"
      - run-eet-suites:
          dsl-args: "FileAppendSuite"
      - run-eet-suites:
          dsl-args: "FileUpdateSuite"
      - run-eet-suites:
          dsl-args: "ProtectedFilesUpdateSuite"
      - run-eet-suites:
          dsl-args: "PermissionSemanticsSpec"
      - run-eet-suites:
          dsl-args: "ExchangeRateControlSuite"
      - run-eet-suites:
          dsl-args: "SysDelSysUndelSpec"
      - run-eet-suites:
          dsl-args: "ExchangeRateControlSuite"
      - run-eet-suites:
          dsl-args: "UpdateFailuresSpec"
      - run-eet-suites:
          dsl-args: "QueryFailuresSpec"
      - run-eet-suites:
          dsl-args: "FileRecordSanityChecks"
      - run-eet-suites:
          dsl-args: "FetchSystemFiles"
      - run:
          name: cat /repo/test-clients/remote-system-files/appProperties.txt
          command: |
            cat /repo/test-clients/remote-system-files/appProperties.txt

      - run-eet-suites:
          dsl-args: "VersionInfoSpec"

  run-smart-contract-scenarios:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-eet-suites:
          dsl-args: "NewOpInConstructorSpecs"
      - run-eet-suites:
          dsl-args: "MultipleSelfDestructsAreSafe"
      - postgres-get-counts
      - run-eet-suites:
          dsl-args: "ContractCallSuite -TLS=on"
      - postgres-verify-counts:
          expected-difference: 17
      - run-eet-suites:
          dsl-args: "ContractCallLocalSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "ContractUpdateSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "ContractDeleteSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "ChildStorageSpecs -TLS=on"
      - run-eet-suites:
          dsl-args: "BigArraySpec -TLS=on"
      - run-eet-suites:
          dsl-args: "SmartContractInlineAssemblySpec -TLS=on"
      - run-eet-suites:
          dsl-args: "OCTokenSpec -TLS=on"
      - run-eet-suites:
          dsl-args: "CharacterizationSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "SmartContractFailFirstSpec -TLS=on"
      - run-eet-suites:
          dsl-args: "SmartContractSelfDestructSpec -TLS=on"
      - run-eet-suites:
          dsl-args: "ChildStorageSpecs"
      - run-eet-suites:
          dsl-args: "-A DeprecatedContractKeySpecs"
      - run-eet-suites:
          dsl-args: "ThresholdRecordCreationSpecs"
      - run-eet-suites:
          dsl-args: "ContractRecordSanityChecks"
      - run-eet-suites:
          dsl-args: "ContractGetBytecodeSuite"

  run-umbrella-freeze-restart-test:
    parameters:
      freeze-pattern-count:
        description: How many repetitions of the freeze pattern should occur
        type: integer
        default: 1
      liveness-pattern-count:
        description: How many repetitions of the liveness pattern should occur
        type: integer
        default: 3
      signed-state-pattern-count:
        description: How many repetitions of the signed state pattern should occur
        type: integer
        default: 1
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run:
          name: Set log level to WARN
          command: /repo/.circleci/scripts/config-log4j-4reg.sh
      - run-umbrella-test
      - run-eet-suites:
          dsl-args: "OneOfEveryTxn"
      - run-eet-suites:
          dsl-args: "MigrationValidationPreSteps"
      - start-freeze:
          failure-log-pattern-sh: /repo/.circleci/scripts/frz-fail-pattern.sh
      - run-eet-suites:
          perf-run: true
          dsl-args: "UmbrellaRedux duration=2,unit=MINUTES,maxOpsPerSec=30,props=regression-mixed_ops.properties,maxPendingOps=50"
      - validate-thaw:
          freeze-pattern-count: << parameters.freeze-pattern-count >>
      - restart-with-validations:
          valid-ss-timeout-secs: 180
          active-status-timeout-secs: 180
          liveness-pattern-count: << parameters.liveness-pattern-count >>
          signed-state-pattern-count: << parameters.signed-state-pattern-count >>
      - run-eet-suites:
          dsl-args: "MigrationValidationPostSteps"
      - run-eet-suites:
          perf-run: true
          dsl-args: "UmbrellaRedux duration=1,unit=MINUTES,maxOpsPerSec=30,props=regression-mixed_ops.properties,maxPendingOps=50"
      - run:
          name: Set log level to INFO
          command: /repo/.circleci/scripts/config-log4j-4normal.sh
      - validate-record-streams


  run-update-feature:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - attach_workspace:
          at: /
      - run:
          name:  Reset client log
          command: |
            cat /dev/null > /repo/test-clients/output/hapi-client.log
      - ensure-testnet-for-reruns
      - run:
          name: Set environmental variable
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/append_bash_profile.sh'
      - run-eet-suites:
          dsl-args: "CryptoTransferSuite"
      - run:
          name: wait state is saved
          command: |
            sleep 60
      - run:
          name: Show java process
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_java_process.sh'
      - run-eet-suites:
          dsl-args: FreezeSuite
      - run:
          name: Show logs before HGCApp restart
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_logs.sh'
      - run:
          name: wait HGCApp restarted
          command: |
            sleep 300
      - run:
          name: Show java process
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_java_process.sh'
      - run:
          name: Show logs after HGCApp restart
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_logs.sh'
      - run-eet-suites:
          dsl-args: "CryptoRecordSanityChecks"
      - run:
          name: Scan new setttings message
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/scan-expected-logs.sh "ERROR: fakeParameter is not a valid setting name" swirlds.log'

  run-update-jar-files:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      new-marker:
        type: string
        description: New string to indicate the chang of source code and jar
        default: 'new version jar'
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - attach_workspace:
          at: /
      - run:
          name:  Reset client log
          command: |
            cat /dev/null > /repo/test-clients/output/hapi-client.log
      - ensure-testnet-for-reruns
      - run:
          name: Set environmental variable
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/append_bash_profile.sh'
      - run:
          name: Scan old string before changing jar files
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/scan-expected-logs.sh "init finished" hgcaa.log'
      - run:
          name: Modify main.java and build new jars
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/build_new_jars.sh "<< parameters.new-marker >>"'
      - run:
          name: Show java process before freeze
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_java_process.sh'
      - run-eet-suites:
          dsl-args: "UpdateServerFiles"
      - run:
          name: wait HGCApp restarted
          no_output_timeout: 4m
          command: |
            sleep 200
      - run:
          name: Show java process
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_java_process.sh'
      - run:
          name: Show logs after HGCApp restart
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/show_logs.sh'
      - run:
          name: Scan new string after restarted
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/scan-expected-logs.sh "<< parameters.new-marker >>" hgcaa.log'

  run-network-sim:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >> # "simulate network outage"
    steps:
      - attach_workspace:
          at: /
      - run:
          name: call script to block tcp ports
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/firewall_create_rules.sh'
      - run-eet-suites:
          dsl-args: "CryptoTransferLoadTest status.preResolve.pause.ms=8000"
          ci-properties-map: mins=50,tps=10,threads=3
      - run:
          name: call script to remove firewall rules
          command: |
            /repo/.circleci/scripts/trap-failable-for-tf-cleanup.sh \
            '/repo/.circleci/scripts/firewall_flush_rules.sh'
      - run:
          name: Show logs after HGCApp restart
          command: |
            /repo/.circleci/scripts/show_logs.sh

  run-comprehensive-functional-test:
    parameters:
      runner:
        type: executor
        default: ci-test-executor
      workflow-name:
        type: string
        default: ""
    executor:
      name: ci-test-executor
      workflow-name:  << parameters.workflow-name >>
    steps:
      - run-eet-suites:
          dsl-args: "BucketAndLegacyThrottlingSpec"
      - run-eet-suites:
          dsl-args: "ControlAccountsExemptForUpdates"
      - run-eet-suites:
          dsl-args: "TopicCreateSpecs"
      - run-eet-suites:
          dsl-args: "SubmitMessageSpecs"
      - run-eet-suites:
          dsl-args: "TopicUpdateSpecs"
      - run-eet-suites:
          dsl-args: "TopicGetInfoSpecs"
      - run-eet-suites:
          dsl-args: "CryptoCreateSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "CryptoRecordSanityChecks -TLS=on"
      - run-eet-suites:
          dsl-args: "SignedTransactionBytesRecordsSuite -TLS=on"
      - run-eet-suites:
          dsl-args: "SuperusersAreNeverThrottled"
      - run-eet-suites:
          dsl-args: "FileRecordSanityChecks"
      - run-eet-suites:
          dsl-args: "VersionInfoSpec"
      - run-eet-suites:
          dsl-args: "PermissionSemanticsSpec"
      - run-eet-suites:
          dsl-args: "SysDelSysUndelSpec"
      - run-eet-suites:
          dsl-args: "NewOpInConstructorSpecs"
      - run-eet-suites:
          dsl-args: "MultipleSelfDestructsAreSafe"
      - run-eet-suites:
          dsl-args: "FetchSystemFiles"
      - run-eet-suites:
          dsl-args: "ChildStorageSpecs"
      - run-eet-suites:
          dsl-args: "DeprecatedContractKeySpecs"
      - run-eet-suites:
          dsl-args: "ThresholdRecordCreationSpecs"
      - run-eet-suites:
          dsl-args: "ContractRecordSanityChecks"
      - run-eet-suites:
          dsl-args: "TopicDeleteSpecs"
      - run-eet-suites:
          dsl-args: "ProtectedFilesUpdateSuite"
      - run-eet-suites:
          dsl-args: "TokenCreateSpecs"
      - run-eet-suites:
          dsl-args: "TokenUpdateSpecs"
      - run-eet-suites:
          dsl-args: "TokenDeleteSpecs"
      - run-eet-suites:
          dsl-args: "TokenTransactSpecs"
      - run-eet-suites:
          dsl-args: "TokenManagementSpecs"
      - run-eet-suites:
          dsl-args: "TokenAssociationSpecs"
      - run-eet-suites:
          dsl-args: "CannotDeleteSystemEntitiesSuite"
      - run-eet-suites:
          dsl-args: "UmbrellaRedux"
